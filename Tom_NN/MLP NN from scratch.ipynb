{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My not very good Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little neural network program. I don't think it's very good. It's slow too.\n",
    "\n",
    "Also, the code is way, way longer than I think it ought to be. However, most of the code is initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic=lambda x:1/(1+np.exp(-x))\n",
    "\n",
    "d_logistic= lambda result: result*(1-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main work here is done by the HiddenLayer class, which computes an output based on the previous layers input, and does the backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,n_in, n_out, weights=None,bias=None):\n",
    "        #Is there a better way to make initilization less long\n",
    "        if weights is None:\n",
    "            weights=(2*np.random.random((n_in,n_out))-1)\n",
    "        if bias is None:\n",
    "            bias=(np.zeros((n_out),dtype=np.float64))\n",
    "        self.n_in=n_in\n",
    "        self.n_out=n_out\n",
    "        self.weights=weights\n",
    "        self.bias=bias\n",
    "        self.output=np.zeros((n_out),dtype=np.float64)\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "        self.delta=np.zeros((n_in),dtype=np.float64)\n",
    "        self.error=np.zeros((n_out),dtype=np.float64)\n",
    "    def forward_prop(self,inputs):\n",
    "        #This is the important part\n",
    "        ins=self.bias+np.dot(inputs,self.weights)\n",
    "        #ins=np.dot(inputs,self.weights)\n",
    "        self.output = logistic(ins)\n",
    "        self.inputs=inputs\n",
    "        #return self.output\n",
    "    def backprop(self,delta,alpha):\n",
    "        #this is also important\n",
    "        self.error=np.array(delta.dot(np.matrix(self.bias).T+self.weights.T))\n",
    "        #self.error=np.array(delta.dot(self.weights.T))\n",
    "        self.back_delta=self.error*d_logistic(self.inputs)\n",
    "        self.weights+=alpha*self.inputs.T.dot(delta)\n",
    "        self.bias-=alpha*delta.sum(axis=0)\n",
    "        #return self.back_delta\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not 100% satisfied with the logic in making the output a whole separate layer. All it does is take in the input from the previous layer and compute the error. However, this is how an people draw a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OutputLayer(object):\n",
    "    def __init__(self,y):\n",
    "        if (len(y.shape)>1):\n",
    "            n_in=y.shape[-1]\n",
    "        else:\n",
    "            #needed in case you want to input a pandas series\n",
    "            y=np.expand_dims(y,axis=1)\n",
    "            n_in=1\n",
    "        self.n_in=n_in\n",
    "        self.y=y\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "    def forward_prop(self,inputs):\n",
    "        self.inputs=inputs\n",
    "    def backprop(self,alpha):\n",
    "        self.error=self.y-self.inputs\n",
    "        self.back_delta=self.error*d_logistic(self.inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the Neural Network itself. The network (`Multi_Layer_Perceptron().layers`) is a list of `Layer` classes that I defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Multi_Layer_Perceptron(object):\n",
    "    def __init__(self,n_layers,features,y,alpha=0.01, n_hidden_paths=None):\n",
    "        self.alpha=alpha\n",
    "        self.features=features\n",
    "        self.n_layers=n_layers\n",
    "        #Set the number of features\n",
    "        if (len(features.shape)>1):\n",
    "            self.n_features=features.shape[-1]\n",
    "        else:\n",
    "            self.n_features=1\n",
    "        #Set the number of output features\n",
    "        if (len(y.shape)>1):\n",
    "            n_out=y.shape[-1]\n",
    "        else:\n",
    "            n_out=1\n",
    "        if n_hidden_paths==None:\n",
    "            n_hidden_paths=self.n_features+1\n",
    "        #Initialize the layers of the network\n",
    "        if n_layers>2:\n",
    "            self.layers=[HiddenLayer(self.n_features,n_hidden_paths)]\n",
    "            if n_layers>3:\n",
    "                self.layers.extend([HiddenLayer(n_hidden_paths,n_hidden_paths) for i in xrange(n_layers-3)])\n",
    "            self.layers.extend([HiddenLayer(n_hidden_paths,n_out),OutputLayer(y)])\n",
    "        elif n_layers==2:\n",
    "            self.layers=[HiddenLayer(self.n_features,n_out),OutputLayer(y)]\n",
    "        else:\n",
    "            raise ValueError('Network must have at least 2 layers, an input and output layer.')\n",
    "    def forward_prop(self,features=None):\n",
    "        if features is None:\n",
    "            features=self.features\n",
    "        self.layers[0].forward_prop(features)\n",
    "        for i in xrange(1,self.n_layers):\n",
    "            self.layers[i].forward_prop(self.layers[i-1].output)\n",
    "    def backprop(self,alpha=None):\n",
    "        if alpha is not None:\n",
    "            self.alpha=alpha\n",
    "        self.layers[-1].backprop(self.alpha)\n",
    "        for i in reversed(xrange(0,self.n_layers-1)):\n",
    "            self.layers[i].backprop(self.layers[i+1].back_delta,self.alpha)\n",
    "    def error(self):\n",
    "        return (np.abs(np.round(self.layers[-1].error))).mean()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of `MLP_Classifier` is to have a syntax that will play well with `sklearn`, so I can use it with `GridSearchCV`, for example. I haven't actually figured out how to get it to play nice with any of those though. It would be great to figure out how to do that.\n",
    "\n",
    "It does the work of running the iterations of forward and backward propogation, in the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP_Classifier(object):\n",
    "    def __init__(self,n_layers=4,alpha=0.01, n_hidden_paths=None,min_it=100,max_it=10000,min_error_delta=1e-10,iter_check=50):\n",
    "        self.n_layers=n_layers\n",
    "        self.alpha=alpha\n",
    "        self.n_hidden_paths=n_hidden_paths\n",
    "        self.min_it=min_it\n",
    "        self.max_it=max_it\n",
    "        self.min_error_delta=min_error_delta\n",
    "        self.iter_check=iter_check\n",
    "        self.iterations=0\n",
    "    def fit(self,features,y):\n",
    "        self.error_delta=1.0\n",
    "        self.last_error=1.0\n",
    "        self.MLPC=Multi_Layer_Perceptron(self.n_layers,features,y,alpha=self.alpha,n_hidden_paths=self.n_hidden_paths)\n",
    "        while (self.iterations<self.max_it) and (((self.error_delta)>self.min_error_delta) or (self.error_delta<0.0)):\n",
    "            for i in xrange(self.iter_check):\n",
    "                self.MLPC.forward_prop()\n",
    "                self.MLPC.backprop()\n",
    "                self.iterations+=1\n",
    "            self.error=self.MLPC.error()\n",
    "            if self.iterations>self.min_it:\n",
    "                self.error_delta=self.last_error-self.error\n",
    "            self.last_error=self.error             \n",
    "    def score(self):\n",
    "        #This doesn't actually compute a useful prediction score. Ooops.\n",
    "        if self.iterations<=0:\n",
    "            return 'You need to fit first'\n",
    "        else:\n",
    "            return self.MLPC.error()\n",
    "    def predict(self,feat):\n",
    "        if self.iterations<=0:\n",
    "            return 'You need to fit first'\n",
    "        else:\n",
    "            self.MLPC.forward_prop(features=feat)\n",
    "            return (self.MLPC.layers[-1].inputs)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test data\n",
    "\n",
    "First I'm going to try this out on a super easy data set: Just some of the 0's and 1's in our digit data set.\n",
    "\n",
    "My computer can't quite have enough memory to handle the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../datapath.txt') as f:\n",
    "    datapath=f.readlines()[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(datapath+'/train.csv', nrows=5000, dtype=np.uint8)\n",
    "pixels=train.columns.drop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train[(train['label']==1)|(train['label']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1052, 785)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm just going to run it for 1000 iterations or until it's not getting any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP=MLP_Classifier(max_it=1000,alpha=0.001,min_error_delta=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(train,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 412 ms, total: 3min 17s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%time MLP.fit(train[pixels],train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019011406844106463"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors=np.round(np.abs(MLP.predict(test[pixels]).flatten()-test['label']))\n",
    "errors.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to lie: 2% wrong is pretty sucky. I bet I could do a lot better, and random forest probably can too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
