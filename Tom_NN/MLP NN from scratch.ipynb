{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic=lambda x:1/(1+np.exp(-x))\n",
    "\n",
    "d_logistic= lambda result: result*(1-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-42784cdbeb1f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-42784cdbeb1f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if weights=None:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,n_in, n_out, weights=None,bias=None):\n",
    "        if weights=None:\n",
    "            weights=2*np.random.random((n_in,n_out))-1\n",
    "        if bias=None:\n",
    "            bias=np.zeros((n_out),dtype=np.float64)\n",
    "        self.weights=weights\n",
    "        self.bias=bias\n",
    "        self.output=np.zeros((n_out),dtype=np.float64)\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "    def forward_prop(inputs):\n",
    "        ins=self.bias+np.dot(self.weights,inputs)\n",
    "        self.inputs=\n",
    "        self.output = logistic(ins)\n",
    "        return self.output\n",
    "    def backprop(error):\n",
    "        delta=np.dot(error*d_logistic(self.output))\n",
    "        self.weights=\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,n_in, n_out, weights=None):\n",
    "        if weights==None:\n",
    "            weights=2*np.random.random((n_in,n_out))-1\n",
    "        #if bias=None:\n",
    "        #    bias=np.zeros((n_out),dtype=np.float64)\n",
    "        self.n_in=n_in\n",
    "        self.n_out=n_out\n",
    "        self.weights=weights\n",
    "        #self.bias=bias\n",
    "        self.output=np.zeros((n_out),dtype=np.float64)\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "        self.delta=np.zeros((n_in),dtype=np.float64)\n",
    "        self.error=np.zeros((n_out),dtype=np.float64)\n",
    "    def forward_prop(self,inputs):\n",
    "        ins=self.bias+np.dot(inputs,self.weights)\n",
    "        #ins=np.dot(inputs,self.weights)\n",
    "        self.inputs=inputs\n",
    "        self.output = logistic(ins)\n",
    "        #return self.output\n",
    "    def backprop(self,delta,alpha):\n",
    "        #delta=np.dot(error*d_logistic(self.output))\n",
    "        self.error=delta.dot(self.weights.T)\n",
    "        self.back_delta=self.error*d_logistic(self.inputs)\n",
    "        self.weights+=alpha*self.inputs.T.dot(delta)\n",
    "        #return self.back_delta\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,n_in, n_out, weights=None,bias=None):\n",
    "        if weights==None:\n",
    "            weights=(2*np.random.random((n_in,n_out))-1)\n",
    "        if bias==None:\n",
    "            bias=(np.zeros((n_out),dtype=np.float64))\n",
    "        self.n_in=n_in\n",
    "        self.n_out=n_out\n",
    "        self.weights=weights\n",
    "        self.bias=bias\n",
    "        self.output=np.zeros((n_out),dtype=np.float64)\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "        self.delta=np.zeros((n_in),dtype=np.float64)\n",
    "        self.error=np.zeros((n_out),dtype=np.float64)\n",
    "    def forward_prop(self,inputs):\n",
    "        #ins=self.bias+np.dot(inputs,self.weights)\n",
    "        ins=np.dot(inputs,self.weights)\n",
    "        self.output = logistic(ins)\n",
    "        self.inputs=inputs\n",
    "        #return self.output\n",
    "    def backprop(self,delta,alpha):\n",
    "        #self.error=np.array(delta.dot(np.matrix(self.bias).T+self.weights.T))\n",
    "        self.error=np.array(delta.dot(self.weights.T))\n",
    "        self.back_delta=self.error*d_logistic(self.inputs)\n",
    "        self.weights-=alpha*self.inputs.T.dot(delta)\n",
    "        #self.bias-=alpha*delta.sum(axis=0)\n",
    "        #return self.back_delta\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OutputLayer(object):\n",
    "    def __init__(self,y):\n",
    "        if (len(y.shape)>1):\n",
    "            n_in=y.shape[-1]\n",
    "        else:\n",
    "            #needed in case you want to input a \n",
    "            y=np.expand_dims(y,axis=1)\n",
    "            n_in=1\n",
    "        self.n_in=n_in\n",
    "        self.y=y\n",
    "        self.inputs=np.zeros((n_in),dtype=np.float64)\n",
    "    def forward_prop(self,inputs):\n",
    "        self.inputs=inputs\n",
    "    def backprop(self,alpha):\n",
    "        self.error=self.y-self.inputs\n",
    "        self.back_delta=self.error*d_logistic(self.inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Multi_Layer_Perceptron(object):\n",
    "    def __init__(self,n_layers,features,y,alpha=0.1, n_hidden_paths=None):\n",
    "        self.alpha=alpha\n",
    "        self.features=features\n",
    "        self.n_layers=n_layers\n",
    "        #Set the number of features\n",
    "        if (len(features.shape)>1):\n",
    "            self.n_features=features.shape[-1]\n",
    "        else:\n",
    "            self.n_features=1\n",
    "        #Set the number of output features\n",
    "        if (len(y.shape)>1):\n",
    "            n_out=y.shape[-1]\n",
    "        else:\n",
    "            n_out=1\n",
    "        if n_hidden_paths==None:\n",
    "            n_hidden_paths=self.n_features+1\n",
    "        #Initialize the layers of the network\n",
    "        if n_layers>2:\n",
    "            self.layers=[HiddenLayer(self.n_features,n_hidden_paths)]\n",
    "            if n_layers>3:\n",
    "                self.layers.extend([HiddenLayer(n_hidden_paths,n_hidden_paths) for i in xrange(n_layers-3)])\n",
    "            self.layers.extend([HiddenLayer(n_hidden_paths,n_out),OutputLayer(y)])\n",
    "        elif n_layers==2:\n",
    "            self.layers=[HiddenLayer(self.n_features,n_out),OutputLayer(y)]\n",
    "        else:\n",
    "            raise ValueError('Network must have at least 2 layers, an input and output layer.')\n",
    "    def forward_prop(self):\n",
    "        self.layers[0].forward_prop(self.features)\n",
    "        for i in xrange(1,self.n_layers):\n",
    "            self.layers[i].forward_prop(self.layers[i-1].output)\n",
    "    def backprop(self,alpha=None):\n",
    "        if alpha != None:\n",
    "            self.alpha=alpha\n",
    "        self.layers[-1].backprop(self.alpha)\n",
    "        for i in reversed(xrange(0,self.n_layers-1)):\n",
    "            self.layers[i].backprop(self.layers[i+1].back_delta,self.alpha)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../datapath.txt') as f:\n",
    "    datapath=f.readlines()[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(datapath+'/train.csv', nrows=1000, dtype=np.uint8)\n",
    "pixels=train.columns.drop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train[(train['label']==1)|(train['label']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP=Multi_Layer_Perceptron(20,train[pixels],train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.54 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "MLP.forward_prop()\n",
    "MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(100):\n",
    "    MLP.forward_prop()\n",
    "    MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7436827433690933e-16"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-1].inputs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47290640394088684"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(MLP.layers[-1].error).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.forward_prop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[1].bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[0].weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (4,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-774544ff03ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_delta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-97-7c07bb7368e2>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, delta, alpha)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#return self.output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (4,3) "
     ]
    }
   ],
   "source": [
    "MLP.layers[0].backprop(MLP.layers[1].back_delta,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, -9.0]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.error.sum() for x in MLP.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP.layers[-2].backprop(MLP.layers[-1].back_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(MLP.layers[-2].back_delta).isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP.layers[-3].backprop(MLP.layers[-2].back_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.layers[-3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27     True\n",
       "28     True\n",
       "29     True\n",
       "       ... \n",
       "755    True\n",
       "756    True\n",
       "757    True\n",
       "758    True\n",
       "759    True\n",
       "760    True\n",
       "761    True\n",
       "762    True\n",
       "763    True\n",
       "764    True\n",
       "765    True\n",
       "766    True\n",
       "767    True\n",
       "768    True\n",
       "769    True\n",
       "770    True\n",
       "771    True\n",
       "772    True\n",
       "773    True\n",
       "774    True\n",
       "775    True\n",
       "776    True\n",
       "777    True\n",
       "778    True\n",
       "779    True\n",
       "780    True\n",
       "781    True\n",
       "782    True\n",
       "783    True\n",
       "784    True\n",
       "Name: 758, dtype: bool"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(MLP.layers[2].weights)[758].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(MLP.layers[3].back_delta)).isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 785)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(MLP.layers[2].weights.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 785)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[3].back_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1],[1,1,1]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn0=np.random.random((3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.60444389,  0.70396007,  0.71766409,  0.56045141,  0.70625022,\n",
       "         0.37125583,  0.40015699,  0.42586033],\n",
       "       [ 0.91846872,  1.3745933 ,  0.87059902,  1.53323425,  0.85016604,\n",
       "         1.3363059 ,  1.08538557,  0.99220826],\n",
       "       [ 1.13431584,  0.86828019,  1.47118578,  1.42484416,  0.79117603,\n",
       "         1.23680575,  0.45710503,  0.77771831],\n",
       "       [ 1.44834067,  1.53891342,  1.62412071,  2.39762701,  0.93509185,\n",
       "         2.20185582,  1.1423336 ,  1.34406624],\n",
       "       [ 1.44834067,  1.53891342,  1.62412071,  2.39762701,  0.93509185,\n",
       "         2.20185582,  1.1423336 ,  1.34406624]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(train['label'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some simpler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1],[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.array([[0],[1],[1],[0],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP=Multi_Layer_Perceptron(5,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix(MLP.layers[0].bias).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41562947,  0.40602554, -0.25208644, -0.11352984],\n",
       "       [-0.66647229,  0.95953573,  0.18824454,  0.67506626],\n",
       "       [-0.65410452, -0.16710501, -0.86443363, -0.54223253],\n",
       "       [-0.90494734,  0.38640518, -0.42410265,  0.24636356],\n",
       "       [-0.90494734,  0.38640518, -0.42410265,  0.24636356]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[0].bias+np.dot(X,MLP.layers[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.matrix([[1],[2],[3],[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0],\n",
       "       [ -2],\n",
       "       [ -6],\n",
       "       [-12]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a)*(1-np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [16]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a)*np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49491751],\n",
       "       [ 0.49504872],\n",
       "       [ 0.49825912],\n",
       "       [ 0.49816858],\n",
       "       [ 0.49816858]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.array(MLP.layers[-1].inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.01374095, -0.04431635,  0.07261224, -0.00525996],\n",
       "        [-0.01720501,  0.05548838, -0.0909176 ,  0.00658599],\n",
       "        [-0.01720736,  0.05549596, -0.09093002,  0.00658689],\n",
       "        [ 0.01372371, -0.04426074,  0.07252113, -0.00525336],\n",
       "        [-0.01720866,  0.05550017, -0.09093692,  0.00658739]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-2].error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5,4) and (5,4) not aligned: 4 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-8dc75bd8b65d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-159-7233783c33de>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, alpha)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_delta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-157-7f71e9487d08>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, delta, alpha)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__rmul__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (5,4) and (5,4) not aligned: 4 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "MLP.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 4), (5, 4), (5, 4), (5, 1)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.back_delta.shape for x in MLP.layers[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[3].back_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP.layers[-1].backprop(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLP.layers[-2].backprop(MLP.layers[-1].back_delta,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02054972, -0.01971989, -0.02422923,  0.01524808])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-2].back_delta.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08092776],\n",
       "       [ 0.17808934],\n",
       "       [ 0.19051578],\n",
       "       [ 0.17255441]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-2].inputs.T.dot(MLP.layers[-1].back_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03241918,  0.03029239,  0.04073021, -0.02268814],\n",
       "       [-0.0537301 , -0.05020525, -0.06750444,  0.03760231],\n",
       "       [-0.05369204, -0.05016968, -0.06745661,  0.03757567],\n",
       "       [ 0.03221911,  0.03010544,  0.04047885, -0.02254812],\n",
       "       [-0.05373424, -0.05020911, -0.06750964,  0.03760521]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(MLP.layers[-1].back_delta.dot(MLP.layers[-2].bias.T+MLP.layers[-2].weights.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24423168]\n",
      " [ 0.75524007]\n",
      " [ 0.75597924]\n",
      " [-0.24441657]\n",
      " [ 0.75558343]]\n",
      "[[-0.596422  ]\n",
      " [ 0.3991783 ]\n",
      " [ 0.40143078]\n",
      " [-0.60266443]\n",
      " [ 0.39733557]]\n",
      "[[-0.0409066 ]\n",
      " [ 0.06697567]\n",
      " [ 0.06973347]\n",
      " [-0.51148095]\n",
      " [ 0.48851905]]\n",
      "[[-0.01557308]\n",
      " [ 0.01684767]\n",
      " [ 0.01699568]\n",
      " [-0.50048469]\n",
      " [ 0.49951531]]\n",
      "[[-0.01135954]\n",
      " [ 0.01176884]\n",
      " [ 0.01184875]\n",
      " [-0.50021406]\n",
      " [ 0.49978594]]\n",
      "[[-0.00935732]\n",
      " [ 0.00951124]\n",
      " [ 0.009567  ]\n",
      " [-0.50013194]\n",
      " [ 0.49986806]]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(60000):\n",
    "    MLP.forward_prop()\n",
    "    MLP.backprop()\n",
    "    if (i % 10000) ==0:\n",
    "        print(MLP.layers[-1].error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-4].error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00180592],\n",
       "       [ 0.99776543],\n",
       "       [ 0.99816564],\n",
       "       [ 0.00237955]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.layers[-1].inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
